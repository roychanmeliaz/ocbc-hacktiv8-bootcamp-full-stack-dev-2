# -*- coding: utf-8 -*-
"""P0W1D3PM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/ardhiraka/FSDS_Guidelines/blob/master/p0/w1/d3pm.ipynb

# Week 1: Day 3 PM // Python: Module, Packages

___

This sections explores Python modules and Python packages, two mechanisms that facilitate modular programming.

Modular programming refers to the process of breaking a large, unwieldy programming task into separate, smaller, more manageable subtasks or modules. Individual modules can then be cobbled together like building blocks to create a larger application.

There are several advantages to modularizing code in a large application:

- **Simplicity**: Rather than focusing on the entire problem at hand, a module typically focuses on **one relatively small portion of the problem**. If you’re working on a single module, you’ll have a smaller problem domain to wrap your head around. This makes development easier and less error-prone.

- **Maintainability**: Modules are typically designed so that they enforce logical boundaries between different problem domains. If modules are written in a way that minimizes interdependency, there is decreased likelihood that modifications to a single module will have an impact on other parts of the program. **(You may even be able to make changes to a module without having any knowledge of the application outside that module.)** This makes it more viable for a team of many programmers to work collaboratively on a large application.

- **Reusability**: Functionality defined in a single module can be easily reused (through an appropriately defined interface) by other parts of the application. **This eliminates the need to recreate duplicate code.**

- **Scoping**: Modules typically define a separate namespace, which helps **avoid collisions** between identifiers in different areas of a program.

## Python Modules: Overview
There are actually three different ways to define a module in Python:

- A module can be written in Python itself such as `Scrapy`,  `Scikit-Learn`.
- A module can be written in C and loaded dynamically at run-time, like the `re` (regular expression) module.
- A built-in module is intrinsically contained in the interpreter, like the `time`, `os`, `sys` modules.

A module’s contents are accessed the same way in all three cases: with the `import` statement.

Here, the focus will mostly be on modules that are written in Python. The cool thing about modules written in Python is that they are exceedingly straightforward to build. All you need to do is create a file that contains legitimate Python code and then give the file a name with a `.py` extension. That’s it! No special syntax or voodoo is necessary.

For example, suppose you have created a file called `person.py` containing the code below :
"""

name = 'zack'
devices = ['laptop', 'smartphone', 'tablet']

def display(arg):
    print(f'arg = {arg}')

"""Several objects are defined in person.py:

- `name` (a string)
- `devices` (a list)
- `display()` (a function)

Assuming `person.py` is in an appropriate location, which you will learn more about shortly, these objects can be accessed by importing the module as follows :

```console
>>> import person
>>> print(person.name)
zack
>>> mod.devices
['laptop', 'smartphone', 'tablet']
>>> mod.display('Good Morning !')
arg = 'Good Morning !'
```
"""

import person
print(person.name)

"""## The Module Search Path

Continuing with the above example, let’s take a look at what happens when Python executes the statement:

`import person`

When the interpreter executes the above `import` statement, it searches for `person.py` in a list of directories assembled from the following sources :

- The directory from which the input script was run or **the current directory** if the interpreter is being run interactively.
- The list of directories contained in the **PYTHONPATH** environment variable, if it is set. (The format for PYTHONPATH is OS-dependent but should mimic the PATH environment variable.)

The resulting search path is accessible in the Python variable `sys.path`, which is obtained from a module named `sys`:

```console
>>> import sys
>>> sys.path

['', '/usr/local/anaconda3/lib/python37.zip', '/usr/local/anaconda3/lib/python3.7', '/usr/local/anaconda3/lib/python3.7/lib-dynload', '/usr/local/anaconda3/lib/python3.7/site-packages', '/usr/local/anaconda3/lib/python3.7/site-packages/aeosa']
```
"""

# If you are using Google Collaboratory, you will find similar results

import sys
print(sys.path)

"""Thus, to ensure your module is found, you need to do one of the following:

- Put `person.py` in the directory where the input script is located or **the current directory**, if interactive.
- **Modify the PYTHONPATH** environment variable to contain the directory where `person.py` is located before starting the interpreter
- Put `person.py` in one of **the directories already contained in the PYTHONPATH** variable

There is actually one additional option : you can put the module file in any directory of your choice and then modify `sys.path` at run-time so that it contains that directory. For example, in this case, your current directory is at `/Users/ardhiraka/`. You could put `person.py` in directory `/Users/ardhiraka/Desktop/H8Py` and then issue the following statements :

```console
>>> sys.path.append(r'/Users/ardhiraka/Desktop/H8Py')
>>> sys.path

['', '/usr/local/anaconda3/lib/python37.zip', '/usr/local/anaconda3/lib/python3.7', '/usr/local/anaconda3/lib/python3.7/lib-dynload', '/usr/local/anaconda3/lib/python3.7/site-packages', '/usr/local/anaconda3/lib/python3.7/site-packages/aeosa', '/usr/local/', '/Users/ardhiraka/Desktop/H8Py']

import person
```

Once a module has been imported, you can determine the location where it was found with the module’s `__file__` attribute:

```console
>>> import mod
>>> mod.__file__
'/Users/ardhiraka/Desktop/H8Py'

>>> import re
>>> re.__file__
'/usr/local/anaconda3/lib/python3.7/re.py'
```

The directory portion of `__file__` should be one of the directories in `sys.path`.

## The import Statement

### Default Syntax

Module contents are made available to the caller with the `import` statement. The `import` statement takes many different forms, shown below.

> `import <module_name>`

Note, that this does not make the module contents directly accessible to the caller. Each module has its own private symbol table, which serves as the global symbol table for all objects defined in the module. Thus, a module creates a separate namespace, as already noted.

The statement import `<module_name>` only places `<module_name>` in the caller’s symbol table. The objects that are defined in the module remain in the module’s private symbol table.

From the caller, objects in the module are only accessible when prefixed with `<module_name>` via dot notation (`.`), as illustrated below.

After the following import statement, `person` is placed into the local symbol table. Thus, `person` has meaning in the caller’s local context:

```console
>>> import person
>>> person
<module 'person' from '/Users/ardhiraka/Desktop/H8Py'>
```

But `name` and `devices` remain in the module’s private symbol table and are not meaningful in the local context:

```console
>>> name
NameError: name 'name' is not defined
>>> display('Good Morning')
NameError: name 'display' is not defined
```

To be accessed in the local context, names of objects defined in the module must be prefixed by `person` :

```console
>>> person.name
'zack'
>>> person.display('Good Morning')
arg = Good Morning
```

Several comma-separated modules may be specified in a single import statement :

`import <module_name_1>, <module_name_2>, <module_name_3>`

---

### from \<module_name> import \<something>

An alternate form of the `import` statement allows individual objects from the module to be imported directly into the caller’s symbol table :

> `from <module_name> import <something>`

Following execution of the above statement, `<something>` can be referenced in the caller’s environment without the `<module_name>` prefix:

```console
>>> from person import name, display
>>> name
'zack'
>>> display('Good Morning')
arg = Good Morning
```

Because this form of `import` places the object names directly into the caller’s symbol table, any objects that already exist with the same name will be overwritten:

```console
>>> devices = ['speaker', 'keyboard']
>>> devices
['speaker', 'keyboard']

>>> from person import devices
>>> devices
['laptop', 'smartphone', 'tablet']
```

It is even possible to indiscriminately `import` everything from a module at one fell swoop:

`from <module_name> import *`

This will place the names of all objects from `<module_name>` into the local symbol table.

For example :

```console
>>> from person import *
>>> name
'zack'
>>> devices
['laptop', 'smartphone', 'tablet']
>>> display('Good Morning')
arg = Good Morning
```

This is **not recommended** in large-scale production code. It’s a bit dangerous because you are entering names into the local symbol table. Unless you know them all well and can be confident there won’t be a conflict, you have a decent chance of overwriting an existing name inadvertently. However, this syntax is quite handy when you are just mucking around with the interactive interpreter, for testing or discovery purposes, because it quickly gives you access to everything a module has to offer without a lot of typing.

---

### from \<module_name> import \<something> as \<alt_name>
    
It is also possible to import individual objects but enter them into the local symbol table with alternate names :

> `from <module_name> import <something> as <alt_name>`

This makes it possible to place names directly into the local symbol table but avoid conflicts with previously existing names :

```console
>>> name = 'alex'
>>> devices = ['tv', 'ac', 'speaker']

>>> from person import name as p_name, devices as p_devices
>>> name
'alex'
>>> p_name
'zack'
>>> devices
['tv', 'ac', 'speaker']
>>> p_devices
['laptop', 'smartphone', 'tablet']
```
---

### import \<module_name> as \<alt_name>

You can also import an entire module under an alternate name:

`import <module_name> as <alt_name>`

```console
>>> import person as my_person
>>> my_person.name
'zack'
>>> my_module.display('Good Morning')
arg = Good Morning
```

Module contents can be imported from within a function definition. In that case, the `import` does not occur until the function is called :

```console
>>> def greetings():
...     from person import display
...     display('Good Morning')
...

>>> greetings()
arg = Good Morning
```

However, **Python 3 does not allow** the indiscriminate `import *` syntax from within a function:

```console
>>> def greetings():
...     from person import *
...     display('Good Morning')
...
SyntaxError: import * only allowed at module level
```
"""

# # This code will get error

# def greetings():
#   from person import *
#   display('Good Morning')

# greetings()

import person
dir(person)

"""## The `dir()` Function

The built-in function `dir()` returns a list of defined names in a namespace. Without arguments, it produces an alphabetically sorted list of names in the current local symbol table:

```console
>>> dir()
['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__']

>>> mylist = [1, 2, 3, 4, 5]
>>> dir()
['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__',
'__package__', '__spec__', 'mylist']

>>> color = 'red'
>>> dir()
['Bar', '__annotations__', '__builtins__', '__doc__', '__loader__', '__name__',
'__package__', '__spec__', 'mylist', 'color']
```

Note how the first call to `dir()` above lists several names that are automatically defined and already in the namespace when the interpreter starts. As new variables are defined (`mylist` and `color`), they appear on subsequent invocations of `dir()`.

---

This can be useful for identifying what exactly has been added to the namespace by an `import` statement:

```console
>>> dir()
['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__',
'__package__', '__spec__']

>>> import person
>>> dir(person)
['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'devices', 'display', 'name']
```

---

When given an argument that is the name of a variable, dir() lists the built-in functions for that particular variable. See the code below.
"""

from person import name, devices
dir(name)

"""## Executing a Module as a Script

Any `.py` file that contains a module is essentially also a Python script, and there isn’t any reason it can’t be executed like one.

Here again is `person.py` as it was defined above :
```py
name = 'zack'
devices = ['laptop', 'smartphone', 'tablet']

def display(arg):
    print(f'arg = {arg}')
```

This can be run as a script:

```console
(base) ardhiraka@rakas-Macbook-Very-Pro ~ %python person.py
(base) ardhiraka@rakas-Macbook-Very-Pro ~ %
```

There are no errors, so it apparently worked. Granted, it’s not very interesting. As it is written, it only defines objects. It doesn’t do anything with them, and it doesn’t generate any output.

---

Let’s modify the above Python module so it does generate some output when run as a script :

`person2.py`
```py
name = 'zack'
devices = ['laptop', 'smartphone', 'tablet']

def display(arg):
    print(f'arg = {arg}')

print(name)
print(devices)
print(display('Good Morning')
```

Now it should be a little more interesting:

```console
(base) ardhiraka@rakas-Macbook-Very-Pro ~ % person2.py
zack
['laptop', 'smartphone', 'tablet']
arg = Good Morning
```

---

Unfortunately, now it also generates output when imported as a module:

```console
>>> import person2
zack
['laptop', 'smartphone', 'tablet']
arg = Good Morning
```

This is probably not what you want. It isn’t usual for a module to generate output when it is imported.

---

Wouldn’t it be nice if you could distinguish between when the file is loaded as a module and when it is run as a standalone script ?

When a `.py` file is imported as a module, Python sets the special dunder variable `__name__` to the name of the module. However, if a file is run as a standalone script, `__name__` is (creatively) set to the string `'__main__'`. Using this fact, you can discern which is the case at run-time and alter behavior accordingly :

`person3.py`

```py
name = 'zack'
devices = ['laptop', 'smartphone', 'tablet']

def display(arg):
    print(f'arg = {arg}')

if (__name__ == '__main__'):
  print('Executing as standalone script')
  print(name)
  print(devices)
  print(display('Good Morning'))
```

Now, if you run as a script, you get output :

```console
(base) ardhiraka@rakas-Macbook-Very-Pro ~ % python person.py
Executing as standalone script
zack
['laptop', 'smartphone', 'tablet']
arg = Good Morning
```

But if you import as a module, you don’t get same output like code above :

```console
>>> import person3
>>> person3.display('Good Morning')
arg = Good Morning
```

### Reloading a Module

For reasons of efficiency, **a module is only loaded once per interpreter session**. That is fine for function and class definitions, which typically make up the bulk of a module’s contents. But a module can contain executable statements as well, usually for initialization. Be aware that these statements will only be executed the first time a module is imported.

Consider the following file `car.py`:

```py
brands = ['honda', 'toyota', 'ford']
print('brands = ', brands)
```

```console
>>> import car
brands = ['honda', 'toyota', 'ford']
>>> import car
>>> import car

>>> car.brands
brands = ['honda', 'toyota', 'ford']
```

The `print()` statement is not executed on subsequent imports. (For that matter, neither is the assignment statement, but as the final display of the value of `car.brands` shows, that doesn’t matter. Once the assignment is made, it sticks.)

If you make a change to a module and need to reload it, you need to either restart the interpreter or use a function called `reload()` from module `importlib`:

```console
>>> import car
brands = ['honda', 'toyota', 'ford']

>>> import car

>>> import importlib
>>> importlib.reload(car)
brands = ['honda', 'toyota', 'ford']
<module 'car' from '/Users/ardhiraka/Desktop/H8Py/car.py'>
```
"""

import car
import importlib
importlib.reload(car)

"""## Python Packages

Suppose you have developed a very large application that includes many modules. As the number of modules grows, it becomes difficult to keep track all of them if they are dumped into one location. This is particularly so if they have similar names or functionality. You might wish for a means of **grouping and organizing** them.

Packages allow for a hierarchical structuring of the module namespace using dot (`.`) notation. **In the same way that modules help avoid collisions between global variable names, packages help avoid collisions between module names.**

Creating a package is quite straightforward, since it makes use of the operating system’s inherent hierarchical file structure. Consider the following arrangement:

<img src='https://files.realpython.com/media/pkg1.9af1c7aea48f.png' />

Here, there is a directory named pkg that contains two modules, `mod1.py` and `mod2.py`. The contents of the modules are:

`mod1.py`

```py
kitchen_sets = ['fork', 'spoon', 'plate']
kitchen_name = 'My Kitchen'
color = 'red'
```

`mod2.py`

```py
artist_kits = ['guitar', 'bass', 'drum']
artist_name = 'Queen'
color = 'yellow'
```

---

Given this structure, if the `pkg` directory resides in a location where it can be found (in one of the directories contained in `sys.path`), you can refer to the two modules with dot notation (`pkg.mod1`, `pkg.mod2`) and `import` them with the syntax you are already familiar with:

`import <folder/package><.module_name_1>, <folder/package>.<module_name_2>`

```console
>>> import pkg.mod1, pkg.mod2
>>> pkg.mod1.kitchen_sets
['fork', 'spoon', 'plate']

>>> pkg.mod2.artist_kits
['guitar', 'bass', 'drum']
```

`from <pakckage>.<module_name> import <something>`

```console
>>> from pkg.mod1 import kitchen_sets
>>> kitchen_sets
['fork', 'spoon', 'plate']
```

`from <package>.<module_name> import <something> as <alt_name>`

```console
>>> from pkg.mod1 import kitchen_sets as ks
>>> ks
['fork', 'spoon', 'plate']
```

---

You can import modules with these statements as well:

```py
from <package_name> import <modules_name>
from <package_name> import <module_name> as <alt_name>
```

```console
>>> from pkg import mod1
>>> mod1.kitchen_sets
['fork', 'spoon', 'plate']

>>> from pkg import mod2 as m2
>>> m2.color
'yellow'
```---

You can import modules with these statements as well:

```py
from <package_name> import <modules_name>
from <package_name> import <module_name> as <alt_name>
```

```console
>>> from pkg import mod1
>>> mod1.kitchen_sets
['fork', 'spoon', 'plate']

>>> from pkg import mod2 as m2
>>> m2.color
'yellow'
```

## PIP

So, what is `pip`? `pip` is a package manager for Python. That means it’s **a tool that allows you to install and manage additional libraries and dependencies** that are not distributed as part of the standard library.

Package management is so important that `pip` has been included with the Python installer since versions 3.4 for Python 3 and 2.7.9 for Python 2, and it’s used by many Python projects, which makes it an essential tool for every Pythonista.

The concept of a package manager might be familiar to you if you are coming from other languages. JavaScript uses `npm` for package management, Ruby uses `gem`, and .NET use `NuGet`. In Python, `pip` has become the standard package manager.

The Python installer installs `pip`, so it should be ready for you to use, unless you installed an old version of Python. You can verify that `pip` is available by running the following command in your console:

```sh
$ pip --version

pip 20.0.2 from /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pip (python 3.7)
```

You should see a similar output displaying the `pip` version, as well as the location and version of Python. If you are using an old version of Python that does not include `pip`, then you can install it by following the instructions for your system in the `pip` installation documentation.
"""

# This is code to install package called TwitterApi

!pip install TwitterAPI

"""### Basic Package Installation

PyPI hosts a very popular library to perform HTTP requests called `requests`. You can learn all about it in its official documentation site. The first step is to install the `requests` package into your environment. You can learn about `pip` supported commands by running it with help:

`pip help`

As you can see, `pip` provides an install command to install packages. You can run it to install the requests package:

`pip install requests`

You should see an output similar to the one above. **You use `pip` with an install command followed by the name of the package you want to install.** `pip` looks for the package in PyPI, calculates its dependencies, and installs them to insure requests will work.

---
"""

pip help

"""You can also see that the current environment is using `pip` version 18.1, but version 19.0.1 is available. It also shows the command you should use to update pip, so let’s do that:

`python -m pip install --upgrade pip`

Notice that you use `python -m` to update `pip`. The `-m` switch tells Python to run a module as an executable. This is necessary because in order for you to update `pip`, the old version has to be uninstalled before installing the new version, and removing it while running the tool can cause errors.

When you run `pip` as a module, Python loads the module in memory and allows the package to be removed while it is being used. You can run packages as if they were scripts if the package provides a top-level script `__main__.py`.

---

Now that you have installed `requests` and upgraded `pip`, you can use the list command to see the packages installed in your environment:

`pip list`

As you can see, `pip` has been upgraded to version 19.0.1 (the latest version at the moment), and `requests` version 2.21.0 has been installed.

The `pip install <package>` command **always looks for the latest version** of the package and installs it. It also searches for dependencies listed in the package metadata and installs those dependencies to insure that the package has all the requirements it needs.

As you can see, multiple packages were installed. You can look at the package metadata by using the show command in `pip`:

`pip show requests`
    
The metadata lists `certifi`, `chardet`, `idna`, and `urllib3` as dependencies, and you can see they were also installed.

With the `requests` package installed, you can modify the example above and see how easy it is to retrieve the contents of a web page:

```py
# In using-requests.py

import requests

url = 'https://www.google.com'
response = requests.get(url)
print(f'Response returned: {response.status_code}, {response.reason}')
print(response.text)
```

You can import the `requests` package as any other standard package because it is now installed in your environment.

As you can see, `requests.get()` handles the HTTP connection for you and returns a response object similar to the original example but with some interface improvements.

You don’t have to deal with the encoding of the page because `requests` will handle that for you in most situations. Still, `requests` provides a flexible interface to handle special cases through the `requests.Response` object.

---

### Using Requirement Files
The `pip` install command always installs the latest published version of a package, but sometimes, you may want to install a specific version that you know works with your code.

You want to create a specification of the dependencies and versions you used to develop and test your application, so there are no surprises when you use the application in production.

**Requirement files allow you to specify exactly which packages and versions should be installed.** Running `pip` help shows that there is a freeze command that outputs the installed packages in requirements format. You can use this command, redirecting the output to a file to generate a requirements file:

```console
pip freeze > requirements.txt
cat requirements.txt
```

The freeze command dumps all the packages and their versions to standard output, so you can redirect the output to a file that can be used to install the exact requirements into another system. The convention is to name this file `requirements.txt`, but you can give it any name you want.

When you want to replicate the environment in another system, you can run `pip install` specifying the requirements file using the `-r` switch:

> `pip install -r requirements.txt`

The versions of the packages will match those listed in requirements.txt:

`pip list`

You can submit the `requirements.tx`t file into source control and use it to create the exact environment in other machines.

### Finding Packages to Use

As you become a more experienced Pythonista, there’ll be a set of packages that you’ll know by heart and that you’ll use in most of your applications. The requests and pytest packages are good candidates to become useful tools in your Python toolbox.

There will be times though when you will need to solve a different problem, and you will want to look for a different tool or library that can help you with it. As you can see above, `pip` help shows that there is a search command that looks for packages published to PyPI.

Let’s see how this command can help us:

`pip help search`

The command takes a set of options listed above and a `<query>`. The query is just a string to search for and will match packages and their descriptions.

Let’s say your application needs to access a service that is using OAuth2 for authorization. Ideally, there is a library that works with requests or with a similar interface that can help us. Let’s search PyPI for it using pip:

`pip search requests oauth`

The search term yields quite an extensive collection of packages. Some of them seem specific to a service or technology like django-oauth. Others look promising, like requests-oauth. Unfortunately, there isn’t much information other than a brief description.

Most of the time, you want to search for packages directly in the PyPI website. PyPI provides search capabilities for its index and a way to filter results by the metadata exposed in the package, like framework, topic, development status, and so on.

A search for the same terms in PyPI yields a lot of results, but you can filter them by different categories. For example, you can expand the Intended Audience and select Developers since you want a library that helps you with developing your application. Also, you probably want a package that is stable and production-ready. You can expand the Development Status category and select Production/Stable:

<img src='https://files.realpython.com/media/search_results.1151d72a4b9b.png' />

You can apply additional filters and tweak the search terms until you find the package that you are looking for.

The results provide a link to the package page, which contains more information and hopefully some documentation. Let’s take a look at the information for requests-oauth2:

<img src='https://files.realpython.com/media/request_oauth_page.a5c341a27a69.png' />

The project page provides more information, and it seems to have a link to the project homepage. The link takes you to the project repository on GitHub. There, you can see some more information about the project and some usage examples.

Finding the original source code repository can be an invaluable resource. There, you can find some hints about the status of the project by looking at the date of the latest commits, number of pull request and open issues, and so forth.

Another option to find a package is to Google it. Widely used Python libraries will show up at the top of google searches, and you should be able to find a link to the package in PyPI or its source code repository.

Finding the right package may take some time and research, but it will also speed up your development process once you find it.

---

### Uninstalling Packages
Once in a while, you will have to uninstall a package. You either found a better library to replace it, or it is something you don’t really need. Uninstalling packages can be a bit tricky.

Notice that, when you installed requests, `pip` installed other dependencies too. The more packages you install, the bigger the chances that multiple packages depend on the same dependency. This is where the show command in pip comes in handy.

Before you uninstall a package, make sure you run the show command for that package:

`pip show requests`

Notice the last two fields Requires and Required-by. The show command tells us that `requests` requires `urllib3`, `certifi`, `chardet`, and `idna`. You probably want to uninstall those two. You can also see that requests is not required by any other package, so it is safe to uninstall it.

You should run the show command against all of the requests dependencies to make sure that no other libraries also depend on them. Once you understand the dependency order of the packages you want to uninstall, you can remove them using the uninstall command:

`pip uninstall certifi`

Uninstalling a package shows you the files that will be removed and will ask for confirmation. If you are sure you want to remove the package because you’ve checked its dependencies and know that nothing else is using it, you can pass a `-y` switch to suppress the file list and confirmation:

`pip uninstall urllib3 -y`

---

### Alternatives to pip

`pip` is an essential tool for all Pythonistas, and it is used by many applications and projects for package management. This tutorial has helped you with the basics, but the Python community is very active in providing great tools and libraries for other developers to use. These include other alternatives to pip that try to simplify and improve package management.

- Conda
- Pipenv
- Poetry
"""